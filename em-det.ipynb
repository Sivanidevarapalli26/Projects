{"metadata":{"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import cv2\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport random\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Activation,Dense,Flatten,MaxPooling2D,BatchNormalization,Conv2D,MaxPool2D,Dropout,Input\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.applications import VGG19\nfrom tensorflow.keras.applications import ResNet50\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale = 1./255,\n                                   validation_split=0.2,\n                                   rotation_range=30,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   width_shift_range=0.3,\n                                   height_shift_range=0.3,\n                                   horizontal_flip = True)\n\ntest_datagen = ImageDataGenerator(rescale = 1./255)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_set = train_datagen.flow_from_directory('../input/emotion-detection-fer/train',\n                                                 target_size=(48,48),\n                                                 color_mode='rgb',\n                                                 batch_size = 128,\n                                                 class_mode = 'categorical',\n                                                 shuffle=True,subset = 'training')\n\nvalidation_set = train_datagen.flow_from_directory('../input/emotion-detection-fer/test',\n                                                 target_size=(48,48),\n                                                 color_mode='rgb',\n                                                 batch_size = 128,\n                                                 class_mode = 'categorical',\n                                                 shuffle=True,subset = 'validation')\ntest_set =test_datagen.flow_from_directory('../input/emotion-detection-fer/test',\n                                                 target_size=(48,48),\n                                                 color_mode='rgb',\n                                                 batch_size = 128,\n                                                 class_mode = 'categorical',\n                                                 shuffle=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_vgg(input_dims=(48,48,3)):\n    vgg19 = VGG19(\n        include_top=False, \n        \n        input_shape=input_dims\n    )\n    img = Input(input_dims,dtype=tf.float32)\n    x = vgg19(img)\n    x = Flatten()(x)\n    x = Dense(7,activation='softmax')(x)\n    model = Model(img,x)\n    \n    return model\nmodel = create_vgg()\nmodel.summary()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def focal_loss(alpha,gamma):\n    def loss(y_true,y_pred):\n        y_pred = K.clip(y_pred, 1e-5,1-1e-5)\n        l = y_true*K.log(y_pred)\n        l = alpha*((1-y_pred)**gamma)*l\n        l = -K.sum(l,axis=-1)\n        return l\n    return loss\nmodel.compile(optimizer = Adam(0.0001), metrics = ['acc'], loss = focal_loss(2.0,4.0))\nhistory=model.fit(training_set,epochs=80,validation_data=validation_set)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_dict=history.history\nimport matplotlib.pyplot as plt\n\ntrain_loss_values = history_dict['loss']\nval_loss_values = history_dict['val_loss']\n\nepochs = range(1, len(history_dict['acc']) + 1)\n\nplt.plot(epochs, train_loss_values, 'bo', label='Training loss')\nplt.plot(epochs, val_loss_values, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_acc = history_dict['acc']\nval_acc = history_dict['val_acc']\nplt.plot(epochs, train_acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(test_set)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('trained.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}